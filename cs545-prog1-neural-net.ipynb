{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt \nfrom sklearn.metrics import confusion_matrix\ndata = pd.read_csv('../input/digit-recognizer/train.csv')\ndata_test = pd.read_csv('../input/digit-recognizer/test.csv')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-07-12T04:20:15.796159Z","iopub.execute_input":"2022-07-12T04:20:15.796558Z","iopub.status.idle":"2022-07-12T04:20:19.138524Z","shell.execute_reply.started":"2022-07-12T04:20:15.796523Z","shell.execute_reply":"2022-07-12T04:20:19.137480Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data.head()\nprint(data_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T04:20:19.140597Z","iopub.execute_input":"2022-07-12T04:20:19.140938Z","iopub.status.idle":"2022-07-12T04:20:19.146132Z","shell.execute_reply.started":"2022-07-12T04:20:19.140905Z","shell.execute_reply":"2022-07-12T04:20:19.144888Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)\nm, n = data.shape\nnp.random.shuffle(data)\ndata_dev = data[0:1000].T\nY_test= data_dev[0]\n\nX_test = data_dev[1:n]\nX_test = X_test / 255\n\n# first 1000 are labels\ndata_train = data[1000:m]\nprint('1_DATASHAPEEEE')\nprint(data_train.shape)\n#data_train = data[30750:m].T\ndata_train = data[20500:m].T\nprint('2_dataShape')\nprint(data_train.shape)\n\n#get Labels from first col\nY_train = data_train[0]\n\n#skip first row\nX_train = data_train[1:n]\nX_train = X_train / 255 \n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T04:20:19.147642Z","iopub.execute_input":"2022-07-12T04:20:19.148138Z","iopub.status.idle":"2022-07-12T04:20:19.843489Z","shell.execute_reply.started":"2022-07-12T04:20:19.148095Z","shell.execute_reply":"2022-07-12T04:20:19.842405Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\ndef init(hidden_units_num):\n    #initialize arguments\n    input_to_hidden_weight_matrix = np.random.rand(hidden_units_num, 784) - 0.5                                                \n    b1 = np.random.rand(hidden_units_num, 1) - 0.5 \n    hidden_to_output_weight_matrix = np.random.rand(10, hidden_units_num) - 0.5                                       \n    b2 = np.random.rand(10, 1) - 0.5 \n    return input_to_hidden_weight_matrix , b1, hidden_to_output_weight_matrix, b2 \n\n\ndef relu(Z):\n    #similar to sigmoid function\n    return np.maximum(Z, 0) \n\n\ndef softmax(Z):\n    #converts vector into a vector of probabilities, \n    A = np.exp(Z) / sum(np.exp(Z))\n    return A\n\n\ndef prop_forward(input_to_hidden_weight_matrix , b1, hidden_to_output_weight_matrix, b2, X, hidden_units_num):\n    #get Z1, the first WEIGHTED SUM (\"the unactivated first layer\")\n    Z1 = input_to_hidden_weight_matrix .dot(X) + b1\n    \n    #first layer\n    input_layer = relu(Z1) \n    \n    #get Z2, second unactivated layer, weighted sum\n    Z2 = hidden_to_output_weight_matrix.dot(input_layer) + b2 \n    #activate function used on Z2 to determine current result) \n    output_layer = softmax(Z2) \n    return Z1, input_layer, Z2, output_layer\n\n\ndef deriv_relu(Z):\n    #for backprop\n    return Z > 0 \n\n#create binary vector\ndef one_hot(Y):\n    one_hot_Y = np.zeros((Y.size, Y.max() + 1)) \n    one_hot_Y[np.arange(Y.size), Y] = 1 \n    #get dimensions correct\n    one_hot_Y = one_hot_Y.T \n    return one_hot_Y\n\n#backward propagation;\n\ndef back_prop(Z1, input_layer, Z2, output_layer, input_to_hidden_weight_matrix , hidden_to_output_weight_matrix, X, Y):\n    '''\n    args: Weighted Sums (Z1, Z2), activated layers (input_layer, output_layer), Weights (input_to_hidden_weight_matrix , hidden_to_output_weight_matrix)\n    retval: second layer weight matrix and predictions\n    dZ2: d/dx Z2 -> hidden_to_output_weight_matrix\n    dhidden_to_output_weight_matrix: d/dx hidden_to_output_weight_matrix-> b2\n    dZ1: d/dx  Z1 -> input_to_hidden_weight_matrix \n    d input_to_hidden_weight_matrix : d/dx input_to_hidden_weight_matrix  -> b1\n    '''\n    one_hot_Y = one_hot(Y)\n    \n    dZ2 = output_layer - one_hot_Y # AKA [(2nd layer predictions) - (one-hot encoded expected values for input)]\n    dhidden_to_output_weight_matrix = 1 / m * dZ2.dot(input_layer.T) # AKA [(1 / size of Y) * (dZ2 (DOT transpose of 1st layer predictions))]\n    db2 = 1 / m * np.sum(dZ2) # AKA [(1 / size of Y) * (sum of all values in dZ2)]\n\n    #dZ1 is \"applying the weights in reverse\"\n    dZ1 = hidden_to_output_weight_matrix.T.dot(dZ2) * deriv_relu(Z1) \n    dinput_to_hidden_weight_matrix  = 1 / m * dZ1.dot(X.T) #[(1 / size of Y) * (dZ2 (DOT transpose of 1st layer predictions)]\n    db1 = 1 / m * np.sum(dZ1) #[(1 / size of Y) * (sum of all values in dZ1)]\n    \n    return dinput_to_hidden_weight_matrix , db1, dhidden_to_output_weight_matrix, db2 \n\n\ndef update(input_to_hidden_weight_matrix , b1, hidden_to_output_weight_matrix, b2, dinput_to_hidden_weight_matrix , db1, dhidden_to_output_weight_matrix, db2, learn_rate, momentum, prev_input_to_hidden_weight_matrix , prev_hidden_to_output_weight_matrix, is_1st_epoch):\n    if is_1st_epoch:\n        del_input_to_hidden_weight_matrix  = learn_rate * dinput_to_hidden_weight_matrix \n        del_hidden_to_output_weight_matrix = learn_rate * dhidden_to_output_weight_matrix\n    else:\n        del_input_to_hidden_weight_matrix  = learn_rate * dinput_to_hidden_weight_matrix  + (momentum * prev_input_to_hidden_weight_matrix )\n        del_hidden_to_output_weight_matrix = learn_rate * dhidden_to_output_weight_matrix + (momentum * prev_hidden_to_output_weight_matrix)\n       \n    \n    input_to_hidden_weight_matrix  = input_to_hidden_weight_matrix  - del_input_to_hidden_weight_matrix \n    b1 = b1 - learn_rate * db1\n    hidden_to_output_weight_matrix = hidden_to_output_weight_matrix - del_hidden_to_output_weight_matrix\n    b2 = b2 - learn_rate * db2\n   \n   \n    return input_to_hidden_weight_matrix , b1, hidden_to_output_weight_matrix, b2, del_input_to_hidden_weight_matrix , del_hidden_to_output_weight_matrix #sending back values, including now \"prev\" delta Ws","metadata":{"execution":{"iopub.status.busy":"2022-07-12T04:20:19.845646Z","iopub.execute_input":"2022-07-12T04:20:19.845980Z","iopub.status.idle":"2022-07-12T04:20:19.861119Z","shell.execute_reply.started":"2022-07-12T04:20:19.845949Z","shell.execute_reply":"2022-07-12T04:20:19.860019Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\ndef get_predictions(output_layer):\n    return np.argmax(output_layer, 0)\n\n\ndef get_accuracy(predictions, Y):\n    return np.sum(predictions == Y) / Y.size \n\ndef trainNN(X, Y, learn_rate, momentum, iterations, hidden_units_num,X_test,Y_test):\n    '''\n    Flow of program:\n        forward propogate:\n        input goes through input_to_hidden_weight_matrix\n        hidden_layer activations go through hid_to_output_matrix--second weiht matrix\n        \n        back propogate:\n        update output layer \n        update output to hidden weights \n        update hidden activation layer\n        update input to hidden weights\n    '''\n    train_acc_array=[]\n    train_time_array=[]\n    acc_array=[]\n    time_array=[]\n    input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2 = init(hidden_units_num)\n    prev_input_to_hidden_weight_matrix  = np.zeros((hidden_units_num, 784))\n    prev_hid_to_output_matrix= np.zeros((10, hidden_units_num))\n    for i in range(iterations):\n        Z1, input_layer, Z2, output_layer = prop_forward(input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, X, hidden_units_num)\n        dinput_to_hidden_weight_matrix , db1, dhid_to_output_matrix, db2 = back_prop(Z1, input_layer, Z2, output_layer, input_to_hidden_weight_matrix , hid_to_output_matrix, X, Y)\n        if i == 0:\n            input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, prev_input_to_hidden_weight_matrix, prev_hid_to_output_matrix = update(input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, dinput_to_hidden_weight_matrix , db1, dhid_to_output_matrix, db2, learn_rate, momentum, prev_input_to_hidden_weight_matrix , prev_hid_to_output_matrix, True)\n        else:\n            input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, prev_input_to_hidden_weight_matrix, prev_hid_to_output_matrix = update(input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, dinput_to_hidden_weight_matrix , db1, dhid_to_output_matrix, db2, learn_rate, momentum, prev_input_to_hidden_weight_matrix , prev_hid_to_output_matrix, False)\n             \n       \n        print(\"epoch... \", i) \n        predictions = get_predictions(output_layer) \n        print(get_accuracy(predictions, Y))\n        accs=(get_accuracy(predictions, Y))\n        train_acc_array.append(accs)\n        train_time_array.append(i)\n \n    \n    \n    for i in range(iterations):\n        Z1, input_layer, Z2, output_layer = prop_forward(input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, X_test, hidden_units_num)\n        dinput_to_hidden_weight_matrix , db1, dhid_to_output_matrix, db2 = back_prop(Z1, input_layer, Z2, output_layer, input_to_hidden_weight_matrix , hid_to_output_matrix, X_test, Y_test)\n        #If first iteration, don't include momentum.Use boolean in else statement\n        if i == 0:\n            input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, prev_input_to_hidden_weight_matrix , prev_hid_to_output_matrix = update(input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, dinput_to_hidden_weight_matrix , db1, dhid_to_output_matrix, db2, learn_rate, momentum, prev_input_to_hidden_weight_matrix , prev_hid_to_output_matrix, True)\n        else:\n            input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, prev_input_to_hidden_weight_matrix , prev_hid_to_output_matrix = update(input_to_hidden_weight_matrix , b1, hid_to_output_matrix, b2, dinput_to_hidden_weight_matrix , db1, dhid_to_output_matrix, db2, learn_rate, momentum, prev_input_to_hidden_weight_matrix, prev_hid_to_output_matrix, False)\n        \n        test_predictions = get_predictions(output_layer)\n        test_accs=(get_accuracy(test_predictions, Y_test))\n        print (test_accs)\n        acc_array.append(test_accs)\n        time_array.append(i)\n        \n    print('ACCARRAY')\n    print(acc_array)\n    conf_mat = confusion_matrix(test_predictions, Y_test)\n    print('TEST CONFUSION MATRIX')\n    print(conf_mat)\n    \n    plt.plot(train_time_array,train_acc_array)\n    plt.plot(time_array,acc_array)\n    plt.title('accuracies over epochs')\n    plt.xlabel('epochs')\n    plt.ylabel('accuracies')\n    plt.show()\n    return prev_input_to_hidden_weight_matrix, b1, hid_to_output_matrix, b2\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-12T04:20:19.862302Z","iopub.execute_input":"2022-07-12T04:20:19.862612Z","iopub.status.idle":"2022-07-12T04:20:19.883857Z","shell.execute_reply.started":"2022-07-12T04:20:19.862584Z","shell.execute_reply":"2022-07-12T04:20:19.882876Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"input_to_hidden_weight_matrix , b1, hidden_to_output_weight_matrix, b2 = trainNN(X_train, Y_train, 0.10, .5, 50, 100, X_test,Y_test )","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-07-12T04:20:19.885180Z","iopub.execute_input":"2022-07-12T04:20:19.885821Z","iopub.status.idle":"2022-07-12T04:20:31.861143Z","shell.execute_reply.started":"2022-07-12T04:20:19.885780Z","shell.execute_reply":"2022-07-12T04:20:31.860104Z"},"trusted":true},"execution_count":24,"outputs":[]}]}